{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarization with Huggingface LLMs\n",
    "\n",
    "- https://python.langchain.com/docs/integrations/llms/huggingface_pipelines\n",
    "- https://huggingface.co/models?pipeline_tag=summarization\n",
    "\n",
    "**Models:**\n",
    "- https://huggingface.co/facebook/bart-large-cnn\n",
    "- https://huggingface.co/google/pegasus-cnn_dailymail\n",
    "- https://huggingface.co/Falconsai/text_summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader, UnstructuredPDFLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from functools import partial\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import collapse_docs, split_list_of_docs\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_transformers.openai_functions import create_metadata_tagger\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import Document, StrOutputParser\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/test_documents/Master Thesis Information.html\n",
      "Loading ./data/test_documents/General Questions MMDS.html\n",
      "Loading ./data/test_documents/Learning Agreements MMDS.html\n",
      "Loading ./data/test_documents/Recognition of Coursework and Examinations Master Business Informatics.html\n",
      "Loading ./data/test_documents/General Questions Master Business Informatics.html\n",
      "Loading ./data/test_documents/MMDS info start page.html\n",
      "Loading ./data/test_documents/Recognition of Coursework and Examinations MMDS.html\n",
      "Loading ./data/test_documents/Master Business Informatics info start page.html\n",
      "Loading ./data/test_documents/Extension of Deadlines MMDS.html\n",
      "Loading ./data/test_documents/Learning Agreements Master Business Informatics.html\n",
      "Loading ./data/test_documents/Extension of Deadlines Master Business Infromatics.html\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file in os.listdir('data/test_documents'):\n",
    "    if file.endswith('.html'):\n",
    "        doc_path = './data/test_documents/' + file\n",
    "        print(f'Loading {doc_path}')\n",
    "        loader = UnstructuredHTMLLoader(doc_path)\n",
    "        documents.extend(loader.load())\n",
    "    #elif file.endswith('.pdf'):\n",
    "    #    pdf_path = './data/test_documents/' + file\n",
    "    #    print(f'Loading {pdf_path}')\n",
    "    #    loader = UnstructuredPDFLoader(pdf_path)\n",
    "    #    documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 11:44:59.726176: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-13 11:44:59.767753: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 11:44:59.767792: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 11:44:59.767817: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 11:44:59.776517: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 11:45:01.096692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/pfs/data5/home/ma/ma_ma/ma_fvogl/chatbot/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "bart = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"facebook/bart-large-cnn\",\n",
    "    task=\"summarization\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "#pegasus = HuggingFacePipeline.from_model_id(\n",
    "#    model_id=\"google/pegasus-cnn_dailymail\",\n",
    "#    task=\"summarization\",\n",
    "#    device_map=\"auto\",\n",
    "#)\n",
    "\n",
    "t5 = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Falconsai/text_summarization\",\n",
    "    task=\"summarization\",\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "gpt = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(docs, llm, max_tokens):\n",
    "    # Prompt and method for converting Document -> str.\n",
    "    document_prompt = PromptTemplate.from_template(\"{page_content}\")\n",
    "    partial_format_document = partial(format_document, prompt=document_prompt)\n",
    "\n",
    "    # A text splitter that recursively splits a document into multiple chunks until\n",
    "    # the maximum chunck size is below a predefined value (without overlap).\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = max_tokens,\n",
    "        chunk_overlap  = 0,\n",
    "        length_function = llm.get_num_tokens,\n",
    "        is_separator_regex = False,\n",
    "    )\n",
    "\n",
    "    # The chain we'll apply to each individual document.\n",
    "    # Returns a summary of the document.\n",
    "    map_chain = (\n",
    "        {\"context\": partial_format_document}\n",
    "        | PromptTemplate.from_template(\"Summarize this content:\\n\\n{context}\")\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # A wrapper chain to keep the original Document metadata\n",
    "    map_as_doc_chain = (\n",
    "        RunnableParallel({\"doc\": RunnablePassthrough(), \"content\": map_chain})\n",
    "        | (lambda x: Document(page_content=x[\"content\"], metadata=x[\"doc\"].metadata))\n",
    "    ).with_config(run_name=\"Summarize (return doc)\")\n",
    "\n",
    "\n",
    "    # The chain we'll repeatedly apply to collapse subsets of the documents\n",
    "    # into a consolidate document until the total token size of our\n",
    "    # documents is below some max size.\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(partial_format_document(doc) for doc in docs)\n",
    "\n",
    "    collapse_chain = (\n",
    "        {\"context\": format_docs}\n",
    "        | PromptTemplate.from_template(\"Collapse this content:\\n\\n{context}\")\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    def get_num_tokens(docs):\n",
    "        return llm.get_num_tokens(format_docs(docs))\n",
    "\n",
    "    def collapse(\n",
    "        docs,\n",
    "        config,\n",
    "        token_max=max_tokens,\n",
    "    ):\n",
    "        collapse_ct = 1\n",
    "        while get_num_tokens(docs) > token_max:\n",
    "            config[\"run_name\"] = f\"Collapse {collapse_ct}\"\n",
    "            invoke = partial(collapse_chain.invoke, config=config)\n",
    "            split_docs = split_list_of_docs(docs, get_num_tokens, token_max)\n",
    "            docs = [collapse_docs(_docs, invoke) for _docs in split_docs]\n",
    "            collapse_ct += 1\n",
    "        return docs\n",
    "\n",
    "    # The chain we'll use to combine our individual document summaries\n",
    "    # (or summaries over subset of documents if we had to collapse the map results)\n",
    "    # into a final summary.\n",
    "\n",
    "    reduce_chain = (\n",
    "        {\"context\": format_docs}\n",
    "        | PromptTemplate.from_template(\"Combine these summaries:\\n\\n{context}\")\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    ).with_config(run_name=\"Reduce\")\n",
    "\n",
    "\n",
    "    # The final full chain for summarizing documents\n",
    "    map_reduce_summarizer = (text_splitter.split_documents | map_as_doc_chain.map() | collapse | reduce_chain).with_config(\n",
    "        run_name=\"Map reduce\"\n",
    "    )\n",
    "\n",
    "    docs_summarized = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"Processing document {i}/{len(docs)-1}\")\n",
    "        summary = map_reduce_summarizer.invoke([doc])\n",
    "        summary_doc = Document(page_content=summary, metadata=doc.metadata)\n",
    "        docs_summarized.append(summary_doc)\n",
    "    print(\"done!\")\n",
    "\n",
    "    return docs_summarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2646 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n",
      "Your max_length is set to 142, but you input_length is only 57. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=28)\n",
      "Your max_length is set to 142, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 2/10\n",
      "Processing document 3/10\n",
      "Processing document 4/10\n",
      "Processing document 5/10\n",
      "Processing document 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but you input_length is only 72. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=36)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 7/10\n",
      "Processing document 8/10\n",
      "Processing document 9/10\n",
      "Processing document 10/10\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "doc_summary_bart = get_summary(documents, llm=bart, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_summary_pegasus = get_summary(documents, llm=pegasus, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 0/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 100. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but you input_length is only 132. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 200, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your max_length is set to 200, but you input_length is only 150. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=75)\n",
      "Your max_length is set to 200, but you input_length is only 63. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=31)\n",
      "Your max_length is set to 200, but you input_length is only 24. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n",
      "Your max_length is set to 200, but you input_length is only 17. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n",
      "Your max_length is set to 200, but you input_length is only 70. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but you input_length is only 132. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 3/10\n",
      "Processing document 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 99. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=49)\n",
      "Your max_length is set to 200, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 200, but you input_length is only 132. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 94. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=47)\n",
      "Your max_length is set to 200, but you input_length is only 114. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=57)\n",
      "Your max_length is set to 200, but you input_length is only 80. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=40)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n",
      "Your max_length is set to 200, but you input_length is only 132. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 142. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=71)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 192. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=96)\n",
      "Your max_length is set to 200, but you input_length is only 31. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 104. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=52)\n",
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 82. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=41)\n",
      "Your max_length is set to 200, but you input_length is only 178. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=89)\n",
      "Your max_length is set to 200, but you input_length is only 132. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n",
      "Your max_length is set to 200, but you input_length is only 125. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=62)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 200, but you input_length is only 54. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=27)\n",
      "Your max_length is set to 200, but you input_length is only 168. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=84)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 9/10\n",
      "Processing document 10/10\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "doc_summary_t5 = get_summary(documents, llm=t5, max_tokens=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document 0/10\n",
      "Processing document 1/10\n",
      "Processing document 2/10\n",
      "Processing document 3/10\n",
      "Processing document 4/10\n",
      "Processing document 5/10\n",
      "Processing document 6/10\n",
      "Processing document 7/10\n",
      "Processing document 8/10\n",
      "Processing document 9/10\n",
      "Processing document 10/10\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "doc_summary_gpt = get_summary(documents, llm=gpt, max_tokens=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>bart_summary</th>\n",
       "      <th>t5_summary</th>\n",
       "      <th>gpt_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./data/test_documents/Master Thesis Informatio...</td>\n",
       "      <td>You are generally required to demonstrate spec...</td>\n",
       "      <td>Combine these summaries: You are generally req...</td>\n",
       "      <td>This content outlines the requirements and pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./data/test_documents/General Questions MMDS.html</td>\n",
       "      <td>The Mannheim Master in Data Science program eq...</td>\n",
       "      <td>Mannheim Master in Data Science covers six maj...</td>\n",
       "      <td>The content covers the Mannheim Master in Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./data/test_documents/Learning Agreements MMDS...</td>\n",
       "      <td>Mannheim Master in Data Science program equips...</td>\n",
       "      <td>Mannheim Master in Data Science Learning Agree...</td>\n",
       "      <td>The Mannheim Master in Data Science program of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./data/test_documents/Recognition of Coursewor...</td>\n",
       "      <td>The master’s program in Business Informatics i...</td>\n",
       "      <td>Combine these summaries: Please verify that th...</td>\n",
       "      <td>This content covers the recognition of coursew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./data/test_documents/General Questions Master...</td>\n",
       "      <td>The master’s program in Business Informatics i...</td>\n",
       "      <td>Combine these summaries: The examination regul...</td>\n",
       "      <td>This content provides comprehensive informatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc  \\\n",
       "0  ./data/test_documents/Master Thesis Informatio...   \n",
       "1  ./data/test_documents/General Questions MMDS.html   \n",
       "2  ./data/test_documents/Learning Agreements MMDS...   \n",
       "3  ./data/test_documents/Recognition of Coursewor...   \n",
       "4  ./data/test_documents/General Questions Master...   \n",
       "\n",
       "                                        bart_summary  \\\n",
       "0  You are generally required to demonstrate spec...   \n",
       "1  The Mannheim Master in Data Science program eq...   \n",
       "2  Mannheim Master in Data Science program equips...   \n",
       "3  The master’s program in Business Informatics i...   \n",
       "4  The master’s program in Business Informatics i...   \n",
       "\n",
       "                                          t5_summary  \\\n",
       "0  Combine these summaries: You are generally req...   \n",
       "1  Mannheim Master in Data Science covers six maj...   \n",
       "2  Mannheim Master in Data Science Learning Agree...   \n",
       "3  Combine these summaries: Please verify that th...   \n",
       "4  Combine these summaries: The examination regul...   \n",
       "\n",
       "                                         gpt_summary  \n",
       "0  This content outlines the requirements and pro...  \n",
       "1  The content covers the Mannheim Master in Data...  \n",
       "2  The Mannheim Master in Data Science program of...  \n",
       "3  This content covers the recognition of coursew...  \n",
       "4  This content provides comprehensive informatio...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries_df = pd.DataFrame({\n",
    "    \"doc\": [d.metadata[\"source\"] for d in doc_summary_gpt],\n",
    "    \"bart_summary\": [d.page_content for d in doc_summary_bart],\n",
    "    #\"pegasus_summary\": [d.page_content for d in doc_summary_pegasus],\n",
    "    \"t5_summary\": [d.page_content for d in doc_summary_t5],\n",
    "    \"gpt_summary\": [d.page_content for d in doc_summary_gpt]\n",
    "})\n",
    "\n",
    "summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_df.to_csv(\"data/summaries.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatbot)",
   "language": "python",
   "name": "chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
