{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and setup vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/test_documents_embedding_test/Extension of Deadlines Master Business Infromatics.html\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file in os.listdir('data/test_documents'):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = './data/test_documents/' + file\n",
    "        print(f'Loading {pdf_path}')\n",
    "        loader = UnstructuredPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif file.endswith('.html'):\n",
    "        doc_path = './data/test_documents/' + file\n",
    "        print(f'Loading {doc_path}')\n",
    "        loader = UnstructuredHTMLLoader(doc_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split documents into text chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunked_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chroma vector db with OpenAIEmbeddings\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "  chunked_documents,\n",
    "  embedding=OpenAIEmbeddings(),\n",
    "  persist_directory='./storage_langchain'\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prompt\n",
    "template = \"\"\"\n",
    "\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "Execute these steps:\n",
    "1 - list the context\n",
    "2 - focus on words like \"optional\" or \"can\" for your answer\n",
    "3 - answer the question. Do not use information outside of the context to answer the question.\n",
    "\n",
    "Your answer should have this format:\n",
    "\n",
    "context:\n",
    "answer:\n",
    "\n",
    "------------------------\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0),\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "### read questions and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('TestQuestions.csv', delimiter=\";\", names=[\"Question\", \"Response\"] )\n",
    "questions = df_questions[\"Question\"]\n",
    "\n",
    "responses = []\n",
    "counter = 0\n",
    "for q in questions:\n",
    "    print(f'q{counter} start')\n",
    "    r = qa_chain({'query': q})['result']\n",
    "    responses.append((q, r))\n",
    "    print(f'q{counter} end')\n",
    "    counter += 1\n",
    "\n",
    "df_responses = pd.DataFrame(responses, columns=[\"Question\", \"Response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_responses.to_csv(\"test_responses_by_langchain_.csv\", sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
