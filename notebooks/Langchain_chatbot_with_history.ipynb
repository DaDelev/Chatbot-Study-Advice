{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chatbot (with chat history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader, UnstructuredPDFLoader\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data and setup vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./data/test_documents/Extension of Deadlines Master Business Infromatics.html\n",
      "Loading ./data/test_documents/Extension of Deadlines MMDS.html\n",
      "Loading ./data/test_documents/General Questions Master Business Informatics.html\n",
      "Loading ./data/test_documents/General Questions MMDS.html\n",
      "Loading ./data/test_documents/Learning Agreements Master Business Informatics.html\n",
      "Loading ./data/test_documents/Learning Agreements MMDS.html\n",
      "Loading ./data/test_documents/Master Business Informatics info start page.html\n",
      "Loading ./data/test_documents/Master Thesis Information.html\n",
      "Loading ./data/test_documents/MMDS info start page.html\n",
      "Loading ./data/test_documents/Modue_Catalog_MSc_Wifo_23_24.pdf\n",
      "Loading ./data/test_documents/Module_Catalog_Appendix_MMDS_23_24.pdf\n",
      "Loading ./data/test_documents/Module_Catalog_MMDS_23_24.pdf\n",
      "Loading ./data/test_documents/PO_MMDS_20.pdf\n",
      "Loading ./data/test_documents/PO_MSc_Wifo_18.pdf\n",
      "Loading ./data/test_documents/Recognition of Coursework and Examinations Master Business Informatics.html\n",
      "Loading ./data/test_documents/Recognition of Coursework and Examinations MMDS.html\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file in os.listdir('data/test_documents'):\n",
    "    if file.endswith('.pdf'):\n",
    "        pdf_path = './data/test_documents/' + file\n",
    "        print(f'Loading {pdf_path}')\n",
    "        loader = UnstructuredPDFLoader(pdf_path)\n",
    "        documents.extend(loader.load())\n",
    "    elif file.endswith('.html'):\n",
    "        doc_path = './data/test_documents/' + file\n",
    "        print(f'Loading {doc_path}')\n",
    "        loader = UnstructuredHTMLLoader(doc_path)\n",
    "        documents.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split documents into text chunks\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunked_documents = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chroma vector db with OpenAIEmbeddings\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "  chunked_documents,\n",
    "  embedding=OpenAIEmbeddings(),\n",
    "  persist_directory='./storage_langchain'\n",
    ")\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "If the question does not provide a specific study program, dont answer the question and ask what the student is studying.\n",
    "Else use the following pieces of context to answer the question at the end.\n",
    "\n",
    "To answer the question execute these steps:\n",
    "1 - list the context\n",
    "2 - focus on words like \"optional\" or \"can\" for your answer\n",
    "3 - answer the question. Do not use information outside of the context to answer the question.\n",
    "\n",
    "Your answer should have this format:\n",
    "\n",
    "context:\n",
    "answer:\n",
    "\n",
    "------------------------\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0),\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\"prompt\": custom_prompt}\n",
    ")\n",
    "\n",
    "# used to store previous questions and answers\n",
    "chat_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Do I have to do any fundamental courses?\"\n",
    "\n",
    "result = qa_chain({'question': query, 'chat_history': chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does that apply if i am studying the master of data science?\"\n",
    "\n",
    "result = qa_chain({'question': query, 'chat_history': chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Does the same apply if I am studying Business Informatics?\"\n",
    "\n",
    "result = qa_chain({'question': query, 'chat_history': chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "print(result['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
