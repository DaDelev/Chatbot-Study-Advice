{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757a4b7a",
   "metadata": {},
   "source": [
    "# Prompt Engineering Tests with Metadata and Study Program-Specific Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d806c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc62cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory='./storage_scaled_w_metadata'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad719fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prompt\n",
    "template = \"\"\"\n",
    "\n",
    "Use the following pieces of context to answer the question at the end.\n",
    "\n",
    "Execute these steps:\n",
    "1 - list the context\n",
    "2 - focus on words like \"optional\" or \"can\" for your answer\n",
    "3 - answer the question. Do not use information outside of the context to answer the question.\n",
    "\n",
    "Your answer should have this format:\n",
    "\n",
    "context:\n",
    "answer:\n",
    "\n",
    "------------------------\n",
    "Context: {context}\n",
    "\n",
    "Question: I am studying in the {study_program} program. {question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "custom_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b540aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Q&A chain for each study program\n",
    "\n",
    "study_programs = [\n",
    "    \"B.Sc. Business Informatics\",\n",
    "    \"M.Sc. Business Informatics\",\n",
    "    \"B.Sc. Mathematics in Business and Economics\",\n",
    "    \"M.Sc. Mathematics in Business and Economics\",\n",
    "    \"Mannheim Master in Data Science\"\n",
    "]\n",
    "\n",
    "qa_chains = {program: RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model='gpt-3.5-turbo', temperature=0),\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k': 5}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt.partial(study_program=program)}\n",
    ") for program in study_programs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e7048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test questions and exemplary answers\n",
    "test_questions = pd.read_csv(\"TestQuestions.csv\", sep=\";\")\n",
    "\n",
    "test_questions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test...\n",
    "\n",
    "#set_verbose(True)\n",
    "\n",
    "#qa_chain = qa_chains[\"B.Sc. Business Informatics\"]\n",
    "#\n",
    "#q = test_questions.iloc[0, 0]\n",
    "#\n",
    "#r = qa_chain({'query': q})\n",
    "#print(r['result'])\n",
    "#\n",
    "#print('\\nSources:')\n",
    "#for source_doc in r['source_documents']:\n",
    "#    print(source_doc)\n",
    "#    print('====================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0163da3",
   "metadata": {},
   "source": [
    "The following code cell iterates over the test questions and then asks them five times. Each time a different Q&A chain with a promt specified to the respective study program is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b48da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_questions = pd.read_csv('TestQuestions.csv', delimiter=\";\")\n",
    "questions = df_questions[\"Question\"]\n",
    "\n",
    "responses = []\n",
    "counter = 0\n",
    "\n",
    "for q in questions:\n",
    "    print(f'q{counter} start (', end=\"\")\n",
    "\n",
    "    r_and_s = []\n",
    "\n",
    "    for i, program in enumerate(study_programs):\n",
    "        print(f\"{i}... \", end=\"\")\n",
    "\n",
    "        response_col_name, source_col_name = f\"Response ({program})\", f\"Source ({program})\"\n",
    "        \n",
    "        # get result\n",
    "        result_object = qa_chains[program]({'query': q})\n",
    "        r = result_object['result']\n",
    "        \n",
    "        # get source documents\n",
    "        source_docs = result_object['source_documents']\n",
    "        sources = []\n",
    "        for doc in source_docs:\n",
    "            sources.append(doc.metadata[\"source\"].replace('./data/scraped_data/', ''))\n",
    "\n",
    "        source = \",\".join(sources)\n",
    "        \n",
    "        r_and_s.append(r)\n",
    "        r_and_s.append(sources)\n",
    "\n",
    "        \n",
    "    # build row\n",
    "    responses.append([q] + r_and_s)\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    print(f')\\nq{counter} end')\n",
    "\n",
    "columns = [\"Question\"]\n",
    "for program in study_programs:\n",
    "    columns.append(f\"Response {program}\")\n",
    "    columns.append(f\"Source {program}\")\n",
    "\n",
    "df_responses = pd.DataFrame(responses, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d909824",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_responses.to_csv(\"data/test_responses/test_responses_metadata_study_program_specific_prompt.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
